创建线程
1.new Thread(){覆盖run犯法}
然后start
2.使用runnable
然后再用thread
使用lamda简化
3.使用futureTASK
线程运行原理
栈与栈帧
线程上下文切换
cpu不再执行当前线程，执行另一个线程的代码
join等待线程运行结束
getstate获取状态
isinterrupt
interrupt:可以唤醒
currentThread
sleep实现防止在while true空转占用cpu
join可以等到正确的结果，等线程运行结束
两阶段终止模式
守护线程
setdaemon（true）
操作系统五状态
初始状态，可运行状态，运行状态，阻塞状态，终止状态
java六种状态
临界区：代码块内存在对共享资源的多线程读写操作这段代码块称为临界区
多个线程在临界区内执行，由于代码的执行序列不同而导致结果无法预测称为发生了竞态条件
synchronized对象锁
保证原子性
常见线程安全类
String
Interger
StringBuffer
Random
Vector
Hashtable
java。util。concurrent下的包，多个线程调用它们同一个实例的某个方法是线程安全的，但是两个方法一起还是有可能出现线程不安全
sting和interger不可变类
java对象头
markword
轻量锁
Moniter(锁)
自旋锁
##并发编程笔记
###第一章并发编程的调整
    ####1.1
    CPU通过给每个线程分配时间片来实现单核多线程执行
    多线程需要多出来创建和上下文切换的开销，不一定快
    使用vmstat可以测量上下文测换次数
    减少上下文切换的方法：无锁并发编程；CAS算法；使用最少线程；协程
    ####1.2
    死锁：使用dump线程来探究是哪里线程出现了错误
    避免死锁方法：避免一个线程同时获取多个锁
                避免一个线程在锁内同时占用多个资源
                尝试使用定时锁
                对于数据库锁，加锁和解锁需要在一个数据库连接里
    ####1，3
    资源限制：在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源
    资源限制问题：如果将某段串行的代码并发执行，因为受限于资源，仍然在串行执行，
                    这时候程序不仅不会加快执行，反而会更慢，因为增加了上下文切
                    换和资源调度的时间
    如何在资源限制情况下进行并发编程：根据不同的资源限制调整程序的并发度
###第二章java并发机制的底层实现原理
    ####2.1
    volatile的定义与实现原理：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，
        线程应该确保通过排他锁单独获得这个变量。如果一个字段被声明成volatile，Java线程内存模型确保所
        有线程看到这个变量的值是一致的。
    CPU术语定义：
        内存屏障：处理器指令，实现对内存操作的顺序限制
        缓冲行：缓冲中可以分配的最小存储单位，处理器填写缓存线时会加载整个缓存线，需要使用多个主内存读周期
        原子操作：不可中断的一个或一系列操作
        缓存行填充：当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个缓存行到适当的缓存
        缓存命中：如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数，而不是从内存读取
        写命中：处理器写操作数到内存缓存时如果存在一个有效的缓存行，会写入缓存而不是内存
        写缺失：一个有效的缓存行被写入不存在的内存区域
    Lock前缀的指令在多核处理器下会引发了两件事：1）将当前处理器缓存行的数据写回到系统内存。2）这个写回内存的操作会使在其他CPU里
        缓存了该内存地址的数据无效。
        如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到系统内存。
            但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理
            器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理
            器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，
            会重新从系统内存中把数据读到处理器缓存里。
    volatile的两条实现原则：Lock前缀指令会引起处理器缓存回写到内存。一个处理器的缓存回写到内存会导致其他处理器的缓存无效
    volatile的使用优化：追加字节优化性能，如果队列的头节点和尾节点都不足64字节的话，处理器会将它们都读到同一个高速缓存行中，在多
        处理器下每个处理器都会缓存同样的头、尾节点，当一个处理器试图修改头节点时，会将整个缓存行锁定，那么在缓存一致性机制的作用
        下，会导致其他处理器不能访问自己高速缓存中的尾节点，而队列的入队和出队操作则需要不停修改头节点和尾节点，所以在多处理器的
        情况下将会严重影响到队列的入队和出队效率
    何时不应该追加到64字节：缓存行非64字节宽的处理器，共享变量不会被频繁地写
    ####2.2synchronized的实现原理与应用
    synchronized实现同步的基础： 对于普通同步方法，锁是当前实例对象； 对于静态同步方法，锁是当前类的Class对象。对于同步方法块，
        锁是Synchonized括号里配置的对象
    Synchonized在JVM里的实现原理：JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使
        用monitorenter和monitorexit指令实现的，而方法同步是使用另外一种方式实现的
    monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必
        须有对应的monitorexit与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到
        monitorenter指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁
    synchronized用的锁是存在Java对象头里的
        java对象头的组成：Mark Word存储对象的hashCode或锁信息；Class Metadata Address存储到对象类型的指针：Array 
            Length数组的长度，如果有的话
    锁的升级与对比：在Java SE 1.6中，锁一共有4种状态，级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几
        个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁
    偏向锁：当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要
        进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经
        获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS
        竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。
    偏向锁的撤销：偏向锁的撤销，需要等待全局安全点（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查
        持有偏向锁的线程是否活着，如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍
        历偏向对象的锁记录，栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，
        最后唤醒暂停的线程。
    轻量级锁加锁：线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，
        官方称为DisplacedMark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，
        如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁
    轻量锁解锁：轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，
        表示当前锁存在竞争，锁就会膨胀成重量级锁；因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级
        成重量级锁，就不会再恢复到轻量级锁状态
    ####2.3原子操作的实现原理
    CPU术语：缓存行：缓存的最小操作
        比较并交换：CAS操作需要输入两个数值，一个旧值和一个新值，比较在操作过程中若旧值没有发生变化，才交换为新值，发生不交换
        CPU流水线：工作方式像工业生产上的装配流水线，在CPU中由5-6个不同功能的电路单元组成一条指令处理流水线，然后将指令差分后由
            他们分别执行，这样就能实现在一个CPU时钟周期完成一条指令，因此提高CPU的运算速度
        内存顺序冲突：一般由假共享引起，假共享是指多个CPU同时修改同一个缓存行的不同部分而引起的其中一个CPU的操作无效，当出现这个
            内存顺序冲突时，CPU必须清空流水线
    处理器实现原子操作：对缓存加锁或总线加锁的方式来实现多处理器之间的原子操作；处理器保证从系统内存中读取或者写入一个字节是
        原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址；复杂的内存操作处理器是不能自动保证其
        原子性的，比如跨总线宽度、跨多个缓存行和跨页表的访问。处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。
    使用总线锁保证原子性：处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK #信号，当一个处理器在总线
        上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占共享内存。
    使用缓存锁保证原子性：在同一时刻，我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间的通信锁住了，这使得
        锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，目前处理器在某些场合下使用缓存锁定代替总线锁定
        来进行优化。
    “缓存锁定”是指内存区域如果被缓存在处理器的缓存行中，并且在Lock操作期间被锁定，那么当它执行锁操作回写到内存时，处理器不在总线
        上声言LOCK #信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改由
        两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时，会使缓存行无效
    不会使用缓存锁定：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line）时，则处理器会调用总线锁定
        有些处理器不支持缓存锁定。对于Intel 486和Pentium处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定
    Java如何实现原子操作：通过锁和循环CAS的方式来实现原子操作
    使用循环CAS实现原子操作：JVM中的CAS操作正是利用了处理器提供的CMPXCHG指令实现的。自旋CAS实现的基本思路就是循环进行CAS操作直到
        成功为止
    CAS实现原子操作的三大问题：ABA问题，循环时间长开销大，以及只能保证一个共享变量的原子操作
    ABA问题。因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，
        那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。
    循环时间长开销大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。
    只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作
        时，循环CAS就无法保证操作的原子性，这个时候就可以用锁  
    使用锁机制实现原子操作：锁机制保证了只有获得锁的线程才能够操作锁定的内存区域。JVM内部实现了很多种锁机制，有偏向锁、轻量级锁和
        互斥锁。有意思的是除了偏向锁，JVM实现锁的方式都用了循环CAS，即当一个线程想进入同步块的时候使用循环CAS的方式来获取锁，当
        它退出同步块的时候使用循环CAS释放锁。   
###第三章java内存模型
    ####3.1Java内存模型的基础     
    并发编程模型的两个关键问题：线程之间如何通信及线程之间如何同步
    通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。
    在共享内存的并发模型里，线程之间共享程序的公共状态，通过写-读内存中的公共状态进行隐式通信。在消息传递的并发模型里，线程之间没
        有公共状态，线程之间必须通过发送消息来显式进行通信
    同步是指程序中用于控制不同线程间操作发生相对顺序的机制。在共享内存并发模型里，同步是显式进行的。程序员必须显式指定某个方法或
        某段代码需要在线程之间互斥执行。在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的   
    Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明    
    Java内存模型的抽象结构：所有实例域、静态域和数组元素都存储在堆内存中，堆内存在线程之间共享；局部变量（Local Variables），方
        法定义参数（Java语言规范称之为Formal Method Parameters）和异常处理器参数（Exception HandlerParameters）不会在线程之间
        共享，它们不会有内存可见性问题，也不受内存模型的影响
    Java线程之间的通信由Java内存模型（本文简称为JMM）控制，JMM决定一个线程对共享变量的写入何时对另一个线程可见：线程之间的共享变
        量存储在主内存（Main Memory）中，每个线程都有一个私有的本地内存（LocalMemory），本地内存中存储了该线程以读/写共享变量的副本
    如果线程A与线程B之间要通信的话，必须要经历下面2个步骤。1）线程A把本地内存A中更新过的共享变量刷新到主内存中去。
        2）线程B到主内存中去读取线程A之前已更新过的共享变量。   
    从源代码到指令序列的重排序：编译器优化的重排序；指令级并行的重排序；内存系统的重排序    
    并发编程模型的分类：现代的处理器使用写缓冲区临时保存向内存写入的数据。写缓冲区可以保证指令流水线持续运行，它可以避免由于处理器
        停顿下来等待向内存写入数据而产生的延迟    
    JMM中内存屏障指令：LL：确保load1数据的装载先于load2及所有后续装载指令的装载
        SS：确保store1数据对其他处理器可见先于load2及所有后续装载指令的存储
        LS：确保load1数据的装载先于store2及所有后续装载指令的存储指令刷新到内存
        SL：确保store1数据对其他处理器可见先于load2及所有后续装载指令的存储
    StoreLoad Barriers是一个“全能型”的屏障，它同时具有其他3个屏障的效果。现代的多处理器大多支持该屏障   
    happens-before简介： 程序顺序规则：一个线程中的每个操作，happens-before于该线程中的任意后续操作。
        监视器锁规则：对一个锁的解锁，happens-before于随后对这个锁的加锁。
        volatile变量规则：对一个volatile域的写，happens- before于任意后续对这个volatile域的读。
        传递性：如果A happens-before B，且B happens-before C，那么Ahappens-before C
    两个操作之间具有happens-before关系，并不意味着前一个操作必须要在后一个操作之前执行！happens-before仅仅要求前一个操作
         （执行的结果）对后一个操作可见，且前一个操作按顺序排在第二个操作之前
    ####3.2重排序
    重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段
    数据依赖性：如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性
        编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序     
    as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、
        runtime和处理器都必须遵守as-if-serial语义
    在不改变程序执行结果的前提下，尽可能提高并行度
    重排序对多线程的影响：在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果
    ####3.3顺序一致性
    顺序一致性内存模型是一个理论参考模型，在设计的时候，处理器的内存模型和编程语言的内存模型都会以顺序一致性内存模型作为参照。
    如果程序是正确同步的，程序的执行将具有顺序一致性（SequentiallyConsistent）——即程序的执行结果与该程序在顺序一致性内存模型中
        的执行结果相同
    顺序一致性内存模型有两大特性。1）一个线程中的所有操作必须按照程序的顺序来执行。2）（不管程序是否同步）所有线程都只能看到一个
        单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。
    同步程序的顺序一致性效果：JMM会在退出临界区和进入临界区这两个关键时间点做一些特别处理，使得线程在这两个时间点具有与顺序一致性
        模型相同的内存视图
    对于未同步或未正确同步的多线程程序，JMM只提供最小安全性：线程执行时读取到的值，要么是之前某个线程写入的值，要么是默认值
        （0，Null，False），JMM保证线程读操作读取到的值不会无中生有（OutOf Thin Air）的冒出来
    为了实现最小安全性，JVM在堆上分配对象时，首先会对内存空间进行清零，然后才会在上面分配对象
    ####3.4volatile的内存含义
    理解volatile特性的一个好方法是把对volatile变量的单个读/写，看成是使用同一个锁对这些单个读/写操作做了同步
    volatile变量自身具有下列特性：可见性。对一个volatile变量的读，总是能看到（任意线程）对这个volatile变量最后的写入。
        ❑ 原子性：对任意单个volatile变量的读/写具有原子性，但类似于volatile++这种复合操作不具有原子性。
    volatile读的内存语义如下。当读一个volatile变量时，JMM会把该线程对应的本地内存置为无效。线程接下来将从主内存中读取共享变量
    线程A写一个volatile变量，实质上是线程A向接下来将要读这个volatile变量的某个线程发出了（其对共享变量所做修改的）消息。
        ❑ 线程B读一个volatile变量，实质上是线程B接收了之前某个线程发出的（在写这个volatile变量之前对共享变量所做修改的）消息。
        ❑ 线程A写一个volatile变量，随后线程B读这个volatile变量，这个过程实质上是线程A通过主内存向线程B发送消息。
    在每个volatile写操作的前面插入一个StoreStore屏障。❑ 在每个volatile写操作的后面插入一个StoreLoad屏障。
        ❑ 在每个volatile读操作的后面插入一个LoadLoad屏障。❑ 在每个volatile读操作的后面插入一个LoadStore屏障。
    ####3.5锁的内存语义
    线程A释放一个锁，实质上是线程A向接下来将要获取这个锁的某个线程发出了（线程A对共享变量所做修改的）消息。
        ❑ 线程B获取一个锁，实质上是线程B接收了之前某个线程发出的（在释放这个锁之前对共享变量所做修改的）消息。
        ❑ 线程A释放锁，随后线程B获取这个锁，这个过程实质上是线程A通过主内存向线程B发送消息。
    公平锁和非公平锁释放时，最后都要写一个volatile变量state。
        ❑ 公平锁获取时，首先会去读volatile变量。
        ❑ 非公平锁获取时，首先会用CAS更新volatile变量，这个操作同时具有volatile读和volatile写的内存语义。
    A线程写volatile变量，随后B线程读这个volatile变量。
        2）A线程写volatile变量，随后B线程用CAS更新这个volatile变量。
        3）A线程用CAS更新一个volatile变量，随后B线程用CAS更新这个volatile变量。
        4）A线程用CAS更新一个volatile变量，随后B线程读这个volatile变量。
    ####final域的内存语义
    对于final域，编译器和处理器要遵守两个重排序规则。1）在构造函数内对一个final域的写入，与随后把这个被构造对象的引用赋值给一个
        引用变量，这两个操作之间不能重排序。2）初次读一个包含final域的对象的引用，与随后初次读这个final域，这两个操作之间不能重排序。
    JMM禁止编译器把final域的写重排序到构造函数之外。2）编译器会在final域的写之后，构造函数return之前，插入一个StoreStore屏障。
        这个屏障禁止处理器把final域的写重排序到构造函数之外。
    写final域的重排序规则可以确保：在引用变量为任意线程可见之前，该引用变量指向的对象的final域已经在构造函数中被正确初始化过了。
        其实，要得到这个效果，还需要一个保证：在构造函数内部，不能让这个被构造对象的引用为其他线程所见，也就是对象引用不能在构造函数中“逸出”
    ####3.7happens-before
    程序员对内存模型的使用。程序员希望内存模型易于理解、易于编程。程序员希望基于一个强内存模型来编写代码。
        ❑ 编译器和处理器对内存模型的实现。编译器和处理器希望内存模型对它们的束缚越少越好，这样它们就可以做尽可能多的优化来提
        高性能。编译器和处理器希望实现一个弱内存模型。
    ####3.8双重检查锁定与盐池初始化
    多个线程试图在同一时间创建对象时，会通过加锁来保证只有一个线程能创建对象。
        ❑ 在对象创建好之后，执行getInstance()方法将不需要获取锁，直接返回已创建好的对象。
    双重检查锁定看起来似乎很完美，但这是一个错误的优化
    intra-thread semantics保证重排序不会改变单线程内的程序执行结果。换句话说，intra-thread semantics允许那些在单线程内，不会改
        变单线程程序执行结果的重排序
    初始化一个类，包括执行这个类的静态初始化和初始化在这个类中声明的静态字段。根据Java语言规范，在首次发生下列任意一种情况时，一
        个类或接口类型T将被立即初始化。
###第四章java并发编程基础
    ####4.1线程简介
    线程优先级：线程分配到的时间片多少也就决定了线程使用处理器资源的多少，而线程优先级就是决定线程需要多或者少分配一些处理器资源
        的线程属性    
    在线程构建的时候可以通过setPriority(int)方法来修改优先级，默认优先级是5，优先级高的线程分配时间片的数量要多于优先级低的线程
    线程优先级不能作为程序正确性的依赖，因为操作系统可以完全不用理会Java线程对于优先级的设定
    线程状态：NEW：初始状态，线程被构建，但是还没有调用start（）方法
        RUNNABLE：运行状态，java线程将操作系统中的就绪和运行两种状态笼统成为“运行中”
        BLOCKED：阻塞状态。表示线程阻塞于锁
        WAITING：等待状态，表示线程机内等待状态，需要等其他线程做出一些特定动作
        TIME_WAITING：超时等待状态，可以在指定的时间自行返回
        TERMINATED：终止状态，表示当前线程已经执行完毕
    Daemon线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持性工作    
    Daemon属性需要在启动线程之前设置，不能在启动线程之后设置。
    ####4.2启动和终止线程
    构造线程：在运行线程之前首先要构造一个线程对象，线程对象在构造的时候需要提供线程所需要的属性，如线程所属的线程组、线程优先级、
        是否是Daemon线程等信息
    启动线程：线程对象在初始化完成之后，调用start()方法就可以启动这个线程。线程start()方法的含义是：当前线程（即parent线程）同步
        告知Java虚拟机，只要线程规划器空闲，应立即启动调用start()方法的线程
    中断：可以理解为线程的一个标识位属性，它表示一个运行中的线程是否被其他线程进行了中断操作
    线程通过检查自身是否被中断来进行响应，线程通过方法isInterrupted()来进行判断是否被中断，也可以调用静态方法
        Thread.interrupted()对当前线程的中断标识位进行复位。如果该线程已经处于终结状态，即使该线程被中断过，在调用该线程对象的
        isInterrupted()时依旧会返回false
    大家对于CD机肯定不会陌生，如果把它播放音乐比作一个线程的运作，那么对音乐播放做出的暂停、恢复和停止操作对应在线程Thread的API
        就是suspend()、resume()和stop()
    中断状态是线程的一个标识位，而中断操作是一种简便的线程间交互方式，而这种交互方式最适合用来取消或停止任务。除了中断以外，还可以
        利用一个boolean变量来控制是否需要停止任务并终止该线程
    ####4.3线程间通信
    关键字volatile可以用来修饰字段（成员变量），就是告知程序任何对该变量的访问均需要从共享内存中获取，而对它的改变必须同步刷新回
        共享内存，它能保证所有线程对变量访问的可见性
    关键字synchronized可以修饰方法或者以同步块的形式来进行使用，它主要确保多个线程在同一个时刻，只能有一个线程处于方法或者同步块
        中，它保证了线程对变量访问的可见性和排他性
    等待/通知机制：一个线程修改了一个对象的值，而另一个线程感知到了变化，然后进行相应的操作，整个过程开始于一个线程，而最终执行
        又是另一个线程
    等待/通知的相关方法：notify()：通知一个在对象上等待的线程，使其从wait()方法返回，而返回的前提是该线程获取了对象的锁
        notifyall():通知所有等待在该对象上的线程
        wait（）：调用该方法的线程进入WAITING状态，只有等待另外线程的通知或被中断才会返回，需要注意，嗲用wait（）方法后，会释放对象的锁
        wait(long):超时等待一段时间，这里的参数时间是毫秒，也是说等待n毫秒，如果没有通知就超时返回
        wait(long.int):对于超时时间更细粒度的控制，可以达到纳秒
    等待/通知机制，是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B调用了对象O的notify()或者notifyAll()方法，线
        程A收到通知后从对象O的wait()方法返回，进而执行后续操作。上述两个线程通过对象O来完成交互，而对象上的wait()和
        notify/notifyAll()的关系就如同开关信号一样，用来完成等待方和通知方之间的交互工作    
    调用wait()、notify()以及notifyAll()时需要注意的细节，如下。
        1）使用wait()、notify()和notifyAll()时需要先对调用对象加锁。
        2）调用wait()方法后，线程状态由RUNNING变为WAITING，并将当前线程放置到对象的等待队列。
        3）notify()或notifyAll()方法调用后，等待线程依旧不会从wait()返回，需要调用notify()或notifAll()的线程释放锁之后，等待线程才有机会从wait()返回。
        4）notify()方法将等待队列中的一个等待线程从等待队列中移到同步队列中，而notifyAll()方法则是将等待队列中所有的线程全部移到同步队列，被移动的线程状态由WAITING变为BLOCKED。
        5）从wait()方法返回的前提是获得了调用对象的锁。
    WaitThread首先获取了对象的锁，然后调用对象的wait()方法，从而放弃了锁并进入了对象的等待队列WaitQueue中，进入等待状态。由于
        WaitThread释放了对象的锁，NotifyThread随后获取了对象的锁，并调用对象的notify()方法，将WaitThread从WaitQueue移到
        SynchronizedQueue中，此时WaitThread的状态变为阻塞状态。NotifyThread释放了锁之后，WaitThread再次获取到锁并从wait()方法返回继续执行。
    管道输入/输出流和普通的文件输入/输出流或者网络输入/输出流不同之处在于，它主要用于线程之间的数据传输，而传输的媒介为内存。管道
        输入/输出流主要包括了如下4种具体实现：PipedOutputStream、PipedInputStream、PipedReader和PipedWriter，前两种面向字节，
        而后两种面向字符
    如果一个线程A执行了thread.join()语句，其含义是：当前线程A等待thread线程终止之后才从thread.join()返回。线程Thread除了提供
        join()方法之外，还提供了join(long millis)和join(long millis, int nanos)两个具备超时特性的方法。这两个超时方法表示，
        如果线程thread在给定的超时时间里没有终止，那么将会从该超时方法中返回
    ThreadLocal，即线程变量，是一个以ThreadLocal对象为键、任意对象为值的存储结构。这个结构被附带在线程上，也就是说一个线程可以根
        据一个ThreadLocal对象查询到绑定在这个线程上的一个值
    Profiler可以被复用在方法调用耗时统计的功能上，在方法的入口前执行begin()方法，在方法调用后执行end()方法，好处是两个方法的调用
        不用在一个方法或者类中，比如在AOP（面向方面编程）中，可以在方法调用前的切入点执行begin()方法，而在方法调用后的切入点执行
        end()方法，这样依旧可以获得方法的执行耗时。
    ####4.4线程应用实例
    开发人员经常会遇到这样的方法调用场景：调用一个方法时等待一段时间（一般来说是给定一个时间段），如果该方法能够在给定的时间段之内
        得到结果，那么将结果立刻返回，反之，超时返回默认结果
    假设超时时间段是T，那么可以推断出在当前时间now+T之后就会超时。定义如下变量。❑ 等待持续时间：REMAINING=T。
        ❑ 超时时间：FUTURE=now+T。这时仅需要wait(REMAINING)即可，在wait(REMAINING)返回之后会将执行：REMAINING=FUTURE-now。
        如果REMAINING小于等于0，表示已经超时，直接退出，否则将继续执行wait(REMAINING)。
    线程池的本质就是使用了一个线程安全的工作队列连接工作者线程和客户端线程，客户端线程将任务放入工作队列后便返回，而工作者线程则
        不断地从工作队列上取出工作并执行。当工作队列为空时，所有的工作者线程均等待在工作队列上，当有客户端提交了一个任务之后会通
        知任意一个工作者线程，随着大量的任务被提交，更多的工作者线程会被唤醒
###第五章java中的锁
    ####5.1Lock接口
    锁是用来控制多个线程访问共享资源的方式，一般来说，一个锁能够防止多个线程同时访问共享资源（但是有些锁可以允许多个线程并发的访
        问共享资源，比如读写锁）    
    Lock接口比synchronized多出来的主要特性
        尝试非阻塞地获取锁：当前线程尝试获取锁，如果这一时刻锁没有被其他线程获取到，则成功获取并且持有锁
        能被中断的获取锁：与synchronized不同，获取到锁的线程能够响应中断，当获取到锁的线程被中断时，中断异常将会被抛出，同时释放锁
        超时获取锁：在指定的截止时间之前获取锁，如果截止时间到了仍旧无法获取锁，则返回
    ####5.2队列同步器
    队列同步器AbstractQueuedSynchronizer（以下简称同步器），是用来构建锁或者其他同步组件的基础框架，它使用了一个int成员变量表示
        同步状态，通过内置的FIFO队列来完成资源获取线程的排队工作，并发包的作者（Doug Lea）期望它能够成为实现大部分同步需求的基础
    同步器是实现锁（也可以是任意同步组件）的关键，在锁的实现中聚合同步器，利用同步器实现锁的语义。可以这样理解二者之间的关系：锁
        是面向使用者的，它定义了使用者与锁交互的接口（比如可以允许两个线程并行访问），隐藏了实现细节；同步器面向的是锁的实现者，
        它简化了锁的实现方式，屏蔽了同步状态管理、线程的排队、等待与唤醒等底层操作。锁和同步器很好地隔离了使用者和实现者所需关注的领域
    重写同步器指定的方法时，需要使用同步器提供的如下3个方法来访问或修改同步状态。❑ getState()：获取当前同步状态。
        ❑ setState(int newState)：设置当前同步状态。❑ compareAndSetState(int expect, int update)：使用CAS设置当前状态，该方法能够保证状态设置的原子性。
    同步器可重写的方法
        protected boolean tryAcquire(int arg):独占式获取同步状态，实现该方法需要查询当前状态并判断同步状态是否符合预期，然后再进行CAS设置同步状态
        protected boolean tryRelease(int arg):独占式释放同步状态，等待获取同步状态的线程将有机会获取同步状态
        protected int tryAcquireShared(int arg):共享式获取同步状态，返回大于等于0的值，表示获取成功，反之，获取失败
        protected boolean tryReleaseShared(int arg):共享式释放同步状态
        protected boolean isHeldExclusively():当前同步器是否在独占模式下被线程占用，一般该方法表示是否被当前线程占用
    同步器提供的模板方法基本上分为3类：独占式获取与释放同步状态、共享式获取与释放同步状态和查询同步队列中的等待线程情况。自定义同
        步组件将使用同步器提供的模板方法来实现自己的同步语义    
    从实现角度分析同步器是如何完成线程同步的，主要包括：同步队列、独占式同步状态获取与释放、共享式同步状态获取与释放以及超时获取
        同步状态等同步器的核心数据结构与模板方法。
    同步队列：同步器依赖内部的同步队列（一个FIFO双向队列）来完成同步状态的管理，当前线程获取同步状态失败时，同步器会将当前线程以
        及等待状态等信息构造成为一个节点（Node）并将其加入同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点中的线程唤醒
        ，使其再次尝试获取同步状态
    同步器包含了两个节点类型的引用，一个指向头节点，而另一个指向尾节点。试想一下，当一个线程成功地获取了同步状态（或者锁），其他
        线程将无法获取到同步状态，转而被构造成为节点并加入到同步队列中，而这个加入队列的过程必须要保证线程安全，因此同步器提供了
        一个基于CAS的设置尾节点的方法：compareAndSetTail(Node expect, Nodeupdate)，它需要传递当前线程“认为”的尾节点和当前节点，
        只有设置成功后，当前节点才正式与之前的尾节点建立关联。
    同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，将会唤醒后继节点，而后继节点将会在获取同步状
        态成功时将自己设置为首节点
    设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来
        保证，它只需要将首节点设置成为原首节点的后继节点并断开原首节点的next引用即可
    独占式同步状态获取与释放：通过调用同步器的acquire(int arg)方法可以获取同步状态，该方法对中断不敏感，也就是由于线程获取同步状
        态失败后进入同步队列中，后续对线程进行中断操作时，线程不会从同步队列中移出
    acquire方法逻辑：首先调用自定义同步器实现的tryAcquire(int arg)方法，该方法保证线程安全的获取同步状态，如果同步状态获取失败，
        则构造同步节点（独占式Node. EXCLUSIVE，同一时刻只能有一个线程成功获取同步状态）并通过addWaiter(Node node)方法将该节点加
        入到同步队列的尾部，最后调用acquireQueued(Node node, intarg)方法，使得该节点以“死循环”的方式获取同步状态。如果获取不到
        则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现
    由于非首节点线程前驱节点出队或者被中断而从等待状态返回，随后检查自己的前驱是否是头节点，如果是则尝试获取同步状态。可以看到节点
        和节点之间在循环检查的过程中基本不相互通信，而是简单地判断自己的前驱是否为头节点，这样就使得节点的释放规则符合FIFO，并且
        也便于对过早通知的处理
    前驱节点为头节点且能够获取同步状态的判断条件和线程进入等待状态是获取同步状态的自旋过程。当同步状态获取成功之后，当前线程从
        acquire(int arg)方法返回，如果对于锁这种并发组件而言，代表着当前线程获取了锁
    共享式同步状态获取与释放：共享式获取与独占式获取最主要的区别在于同一时刻能否有多个线程同时获取到同步状态。以文件的读写为例，
        如果一个程序在对文件进行读操作，那么这一时刻对于该文件的写操作均被阻塞，而读操作能够同时进行。写操作要求对资源的独占式访
        问，而读操作可以是共享式访问
    独占式超时获取同步状态：通过调用同步器的doAcquireNanos(int arg, long nanosTimeout)方法可以超时获取同步状态，即在指定的时间
        段内获取同步状态，如果获取到同步状态则返回true，否则，返回false。
    ####5.3重入锁
    重入锁ReentrantLock，顾名思义，就是支持重进入的锁，它表示该锁能够支持一个线程对资源的重复加锁。除此之外，该锁的还支持获取锁时
        的公平和非公平性选择。
    公平的锁机制往往没有非公平的效率高，但是，并不是任何场景都是以TPS作为唯一的指标，公平锁能够减少“饥饿”发生的概率，等待越久的请
        求越是能够得到优先满足
    实现重进入：重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被锁所阻塞，该特性的实现需要解决以下两个问题
        1）线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次成功获取
        2）锁的最终释放。线程重复n次获取了锁，随后在第n次释放该锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自
        增，计数表示当前锁被重复获取的次数，而锁被释放时，计数自减，当计数等于0时表示锁已经成功释放
    公平与非公平获取锁的区别：公平性与否是针对获取锁而言的，如果一个锁是公平的，那么锁的获取顺序就应该符合请求的绝对时间顺序，也就是FIFO
    ####5.4读写锁
    保证写操作对读操作的可见性以及并发性的提升之外，读写锁能够简化读写交互场景的编程方式。假设在程序中定义一个共享的用作缓存数据
        结构，它大部分时间提供读服务（例如查询和搜索），而写操作占有的时间很少，但是写操作完成之后的更新需要对后续的读服务可见
    ReadWriteLock仅定义了获取读锁和写锁的两个方法，即readLock()方法和writeLock()方法，而其实现——ReentrantReadWriteLock，除了
        接口方法之外，还提供了一些便于外界监控其内部工作状态的方法。
    写操作put(String key, Object value)方法和clear()方法，在更新HashMap时必须提前获取写锁，当获取写锁后，其他线程对于读锁和写
        锁的获取均被阻塞，而只有写锁被释放之后，其他读写操作才能继续。Cache使用读写锁提升读操作的并发性，也保证每次写操作对所有的
        读写操作的可见性，同时简化了编程方式
    读写状态的设计：读写锁同样依赖自定义同步器来实现同步功能，而读写状态就是其同步器的同步状态。回想ReentrantLock中自定义同步器
        的实现，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态（一个整型变量）上维护多个读线程和一
        个写线程的状态，使得该状态的设计成为读写锁实现的关键。
    写锁的获取与释放：写锁是一个支持重进入的排它锁。如果当前线程已经获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经
        被获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态
    读锁的获取与释放：读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他写线程访问（或者写状态为0）时，读锁总会被
        成功地获取，而所做的也只是（线程安全的）增加读状态。如果当前线程已经获取了读锁，则增加读状态。如果当前线程在获取读锁时，
        写锁已被其他线程获取，则进入等待状态。
    锁降级：锁降级指的是写锁降级成为读锁。如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。
        锁降级是指把持住（当前拥有的）写锁，再获取到读锁，随后释放（先前拥有的）写锁的过程。
    ####5.5LockSupport工具
    LockSupport定义了一组以park开头的方法用来阻塞当前线程，以及unpark(Thread thread)方法来唤醒一个被阻塞的线
        程。Park有停车的意思，假设线程为车辆，那么park方法代表着停车，而unpark方法则是指车辆启动离开
    ####5.6Conditon接口
    任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、wait(long timeout)、notify()以及
        notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式。Condition接口也提供了类似Object的监视器
        方法，与Lock配合可以实现等待/通知模式，但是这两者在使用方式以及功能特性上还是有差别的
    Condition定义了等待/通知两种类型的方法，当前线程调用这些方法时，需要提前获取到Condition对象关联的锁。Condition对象是由Lock
        对象（调用Lock对象的newCondition()方法）创建出来的，换句话说，Condition是依赖Lock对象的
    ConditionObject是同步器AbstractQueuedSynchronizer的内部类，因为Condition的操作需要获取相关联的锁，所以作为同步器的内部类
        也较为合理。每个Condition对象都包含着一个队列（以下称为等待队列），该队列是Condition对象实现等待/通知功能的关键。
    等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程，如果一个线程调用了
        Condition.await()方法，那么该线程将会释放锁、构造成节点加入等待队列并进入等待状态。
    调用Condition的await()方法（或者以await开头的方法），会使当前线程进入等待队列并释放锁，同时线程状态变为等待状态。当从
        await()方法返回时，当前线程一定获取了Condition相关联的锁
    调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到同步队列中。
###第六章java并发容器和框架
    ####6.1 ConcurrentHashMap的实现原理与使用
    在并发编程中使用HashMap可能导致程序死循环。而使用线程安全的HashTable效率又非常低下，基于以上两个原因，便有了
        ConcurrentHashMap的登场机会        
    在多线程环境下，使用HashMap进行put操作会引起死循环，导致CPU利用率接近100%，所以在并发情况下不能使用HashMap；HashMap在并发执
        行put操作时会引起死循环，是因为多线程会导致HashMap的Entry链表形成环形数据结构，一旦形成环形数据结构，Entry的next节点永
        远不为空，就会产生死循环获取Entry
    HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable
        的同步方法，其他线程也访问HashTable的同步方法时，会进入阻塞或轮询状态。
    HashTable容器在竞争激烈的并发环境下表现出效率低下的原因是所有访问HashTable的线程都必须竞争同一把锁，假如容器里有多把锁，每一
        把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效提高并发访问
        效率，这就是ConcurrentHashMap所使用的锁分段技术。首先将数据分成一段一段地存储，然后给每一段数据配一把锁，当一个线程占用
        锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问
    ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁（ReentrantLock），在ConcurrentHashMap
        里扮演锁的角色；HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组。Segment的结构和HashMap类似，
        是一种数组和链表结构。一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素，每个Segment守护着一个
        HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得与它对应的Segment锁
    ConcurrentHashMap初始化方法是通过initialCapacity、loadFactor和concurrencyLevel等几个参数来初始化segment数组、段偏移量
        segmentShift、段掩码segmentMask和每个segment里的HashEntry数组来实现的。
    Segment的get操作实现非常简单和高效。先经过一次再散列，然后使用这个散列值通过散列运算定位到Segment，再通过散列算法定位到元素
    由于put方法里需要对共享变量进行写入操作，所以为了线程安全，在操作共享变量时必须加锁。put方法首先定位到Segment，然后在Segment
        里进行插入操作。插入操作需要经历两个步骤，第一步判断是否需要对Segment里的HashEntry数组进行扩容，第二步定位添加元素的位置，
        然后将其放在HashEntry数组里
    在扩容的时候，首先会创建一个容量是原来容量两倍的数组，然后将原数组里的元素进行再散列后插入到新的数组里。为了高效，
        ConcurrentHashMap不会对整个容器进行扩容，而只对某个segment进行扩容
    如果要统计整个ConcurrentHashMap里元素的大小，就必须统计所有Segment里元素的大小后求和。Segment里的全局变量count是一个volatile
        变量，那么在多线程场景下，是不是直接把所有Segment的count相加就可以得到整个ConcurrentHashMap大小了呢？不是的，虽然相加时
        可以获取每个Segment的count的最新值，但是可能累加前使用的count发生了变化，那么统计结果就不准了
    ####6.2ConcurrentLinkedQueue
    在并发编程中，有时候需要使用线程安全的队列。如果要实现一个线程安全的队列有两种方式：一种是使用阻塞算法，另一种是使用非阻塞算法。
        使用阻塞算法的队列可以用一个锁（入队和出队用同一把锁）或两个锁（入队和出队用不同的锁）等方式来实现。非阻塞的实现方式则可以
        使用循环CAS的方式来实现。
    ConcurrentLinkedQueue是一个基于链接节点的无界线程安全队列，它采用先进先出的规则对节点进行排序，当我们添加一个元素的时候，它
        会添加到队列的尾部；当我们获取一个元素时，它会返回队列头部的元素。它采用了“wait-free”算法（即CAS算法）来实现，该算法在
        Michael&Scott算法上进行了一些修改
    入队列就是将入队节点添加到队列的尾部添加元素1。队列更新head节点的next节点为元素1节点。又因为tail节点默认情况下等于head节点，
        所以它们的next节点都指向元素1节点。❑ 添加元素2。队列首先设置元素1节点的next节点为元素2节点，然后更新tail节点指向元素2节点
        ❑ 添加元素3，设置tail节点的next节点为元素3节点。❑ 添加元素4，设置元素3的next节点为元素4节点，然后将tail节点指向元素4节点
    第一是定位出尾节点；第二是使用CAS算法将入队节点设置成尾节点的next节点，如不成功则重试。
    tail节点并不总是尾节点，所以每次入队都必须先通过tail节点来找到尾节点。尾节点可能是tail节点，也可能是tail节点的next节点。代码
        中循环体中的第一个if就是判断tail是否有next节点，有则表示next节点可能是尾节点。
    p.casNext（null，n）方法用于将入队节点设置为当前队列尾节点的next节点，如果p是null，表示p是当前队列的尾节点，如果不为null，表
        示有其他线程更新了尾节点，则需要重新获取当前队列的尾节点
    出队列的就是从队列里返回一个节点元素，并清空该节点对元素的引用
    并不是每次出队时都更新head节点，当head节点里有元素时，直接弹出head节点里的元素，而不会更新head节点。只有当head节点里没有元素
        时，出队操作才会更新head节点
    ####java中的阻塞队列
    阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作支持阻塞的插入和移除方法。1）支持阻塞的插入方法：意思
        是当队列满时，队列会阻塞插入元素的线程，直到队列不满。2）支持阻塞的移除方法：意思是在队列为空时，获取元素的线程会等待队列
        变为非空
    JDK 7提供了7个阻塞队列，如下。
        ❑ ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。
        ❑ LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列。
        ❑ PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。
        ❑ DelayQueue：一个使用优先级队列实现的无界阻塞队列。
        ❑ SynchronousQueue：一个不存储元素的阻塞队列。
        ❑ LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。
        ❑ LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列
    ArrayBlockingQueue是一个用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证线程公平的
        访问队列，所谓公平访问队列是指阻塞的线程，可以按照阻塞的先后顺序访问队列，即先阻塞线程先访问队列。非公平性是对先等待的线程
        是非公平的，当队列可用时，阻塞的线程都可以争夺访问队列的资格，有可能先阻塞的线程最后才访问队列。为了保证公平性，通常会降低吞吐量。
    阻塞队列的实现原理：使用通知模式实现。所谓通知模式，就是当生产者往满的队列里添加元素时会阻塞住生产者，当消费者消费了一个队列中
        的元素后，会通知生产者当前队列可用。
    unsafe.park是个native方法，代码如下。public native void park(boolean isAbsolute, long time);park这个方法会阻塞当前线程，
        只有以下4种情况中的一种发生时，该方法才会返回。
        ❑ 与park对应的unpark执行或已经执行时。“已经执行”是指unpark先执行，然后再执行park的情况。
        ❑ 线程被中断时。
        ❑ 等待完time参数指定的毫秒数时。
        ❑ 异常现象发生时，这个异常现象没有任何原因。
    ####6.4Fork/Join框架
    Fork/Join框架是Java 7提供的一个用于并行执行任务的框架，是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结
        果的框架。我们再通过Fork和Join这两个单词来理解一下Fork/Join框架。Fork就是把一个大任务切分为若干子任务并行的执行，Join就
        是合并这些子任务的执行结果，最后得到这个大任务的结果。
    工作窃取（work-stealing）算法是指某个线程从其他队列里窃取任务来执行。那么，为什么需要使用工作窃取算法呢？假如我们需要做一个比
        较大的任务，可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，把这些子任务分别放到不同的队列里，并为每个队列
        创建一个单独的线程来执行队列里的任务，线程和队列一一对应。
    步骤1 分割任务。首先我们需要有一个fork类来把大任务分割成子任务，有可能子任务还是很大，所以还需要不停地分割，直到分割出的子任务
        足够小。步骤2 执行任务并合并结果。分割的子任务分别放在双端队列里，然后几个启动线程分别从双端队列里获取任务执行。子任务执行
        完的结果都统一放在一个队列里，启动一个线程从队列里拿数据，然后合并这些数据。
    Fork/Join使用两个类来完成以上两件事情。①ForkJoinTask：我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中
        执行fork()和join()操作的机制。通常情况下，我们不需要直接继承ForkJoinTask类，只需要继承它的子类，Fork/Join框架提供了以下
        两个子类。❑ RecursiveAction：用于没有返回结果的任务。❑ RecursiveTask：用于有返回结果的任务。②ForkJoinPool：ForkJoinTask
        需要通过ForkJoinPool来执行。任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队
        列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务。
    ForkJoinPool由ForkJoinTask数组和ForkJoinWorkerThread数组组成，ForkJoinTask数组负责将存放程序提交给ForkJoinPool的任务，而
        ForkJoinWorkerThread数组负责执行这些任务
###第七章java中的13个原子操作类    
    ####7.1原子更新基本类型类
    Atomic包提供了以下3个类。❑ AtomicBoolean：原子更新布尔类型。❑ AtomicInteger：原子更新整型。❑ AtomicLong：原子更新长整型
    AtomicInteger的常用方法如下。❑ int addAndGet（int delta）：以原子方式将输入的数值与实例中的值（AtomicInteger里的value）相
        加，并返回结果。❑ boolean compareAndSet（int expect，int update）：如果输入的数值等于预期值，则以原子方式将该值设置为
        输入的值。❑ int getAndIncrement()：以原子方式将当前值加1，注意，这里返回的是自增前的值。❑ void lazySet（int newValue）
        ：最终会设置成newValue，使用lazySet设置值后，可能导致其他线程在之后的一小段时间内还是可以读到旧的值。❑ int getAndSet
        （int newValue）：以原子方式设置为newValue的值，并返回旧值
    ####7.2原子更新基本数组
    Atomic包提供了以下4个类。❑ AtomicIntegerArray：原子更新整型数组里的元素。❑ AtomicLongArray：原子更新长整型数组里的元素。
        ❑ AtomicReferenceArray：原子更新引用类型数组里的元素
    ####7.3原子更新引用类型
    原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包
        提供了以下3个类。❑ AtomicReference：原子更新引用类型。❑ AtomicReferenceFieldUpdater：原子更新引用类型里的字段。
        ❑ AtomicMarkableReference：原子更新带有标记位的引用类型。可以原子更新一个布尔类型的标记位和引用类型。构造方法是
        AtomicMarkableReference（V initialRef, booleaninitialMark）。
    ####7.4原子更新字段类
    Atomic包提供了以下3个类进行原子字段更新。❑ AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。
        ❑ AtomicLongFieldUpdater：原子更新长整型字段的更新器。❑ AtomicStampedReference：原子更新带有版本号的引用类型。该类将
        整数值与引用关联起来，可用于原子的更新数据和数据的版本号，可以解决使用CAS进行原子更新时可能出现的ABA问题。
###第八章java中的并发工具类
    ####8.1等待多线程完成的CountDownLatch
    CountDownLatch允许一个或多个线程等待其他线程完成操作    
    当我们调用CountDownLatch的countDown方法时，N就会减1，CountDownLatch的await方法会阻塞当前线程，直到N变成零。由于countDown
        方法可以用在任何地方，所以这里说的N个点，可以是N个线程，也可以是1个线程里的N个执行步骤。用在多个线程时，只需要把这个
        CountDownLatch的引用传递到线程里即可。
    ####8.2同步屏障CyclicBarrier
    CyclicBarrier的字面意思是可循环使用（Cyclic）的屏障（Barrier）。它要做的事情是，让一组线程到达一个屏障（也可以叫同步点）时被
        阻塞，直到最后一个线程到达屏障时，屏障才会开门，所有被屏障拦截的线程才会继续运行。
    CyclicBarrier可以用于多线程计算数据，最后合并计算结果的场景。例如，用一个Excel保存了用户所有银行流水，每个Sheet保存一个账户
        近一年的每笔银行流水，现在需要统计用户的日均银行流水，先用多线程处理每个sheet里的银行流水，都执行完之后，得到每个sheet的
        日均银行流水，最后，再用barrierAction用这些线程的计算结果
    CountDownLatch的计数器只能使用一次，而CyclicBarrier的计数器可以使用reset()方法重置。所以CyclicBarrier能处理更为复杂的业务
        场景。例如，如果计算发生错误，可以重置计数器，并让线程重新执行一次。
    ####8.3控制并发线程数的Semaphore
    Semaphore（信号量）是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源。
    Semaphore可以用于做流量控制，特别是公用资源有限的应用场景，比如数据库连接。假如有一个需求，要读取几万个文件的数据，因为都是
        IO密集型任务，我们可以启动几十个线程并发地读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个，这时
        我们必须控制只有10个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。
    ####8.4线程间交换数据的Exchanger
    Exchanger（交换者）是一个用于线程间协作的工具类。Exchanger用于进行线程间的数据交换。它提供一个同步点，在这个同步点，两个线程
        可以交换彼此的数据。这两个线程通过exchange方法交换数据，如果第一个线程先执行exchange()方法，它会一直等待第二个线程也执行
        exchange方法，当两个线程都到达同步点时，这两个线程就可以交换数据，将本线程生产出来的数据传递给对方。
    Exchanger可以用于遗传算法，遗传算法里需要选出两个人作为交配对象，这时候会交换两人的数据，并使用交叉规则得出2个交配结果。
        Exchanger也可以用于校对工作，比如我们需要将纸制银行流水通过人工的方式录入成电子银行流水，为了避免错误，采用AB岗两人进行录
        入，录入到Excel之后，系统需要加载这两个Excel，并对两个Excel数据进行校对，看看是否录入一致
###第九章java中的线程池
    在开发过程中，合理地使用线程池能够带来3个好处。第一：降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。
        第二：提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。第三：提高线程的可管理性。线程是稀缺资源，如果
        无限制地创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一分配、调优和监控。但是，要做到合理利用线程
        池，必须对其实现原理了如指掌        
    ####9.1线程池的实现原理
    当提交一个新任务到线程池时，线程池的处理流程如下。1）线程池判断核心线程池里的线程是否都在执行任务。如果不是，则创建一个新的工
        作线程来执行任务。如果核心线程池里的线程都在执行任务，则进入下个流程。2）线程池判断工作队列是否已经满。如果工作队列没有满，
        则将新提交的任务存储在这个工作队列里。如果工作队列满了，则进入下个流程。3）线程池判断线程池的线程是否都处于工作状态。如果
        没有，则创建一个新的工作线程来执行任务。如果已经满了，则交给饱和策略来处理这个任务。
    ThreadPoolExecutor执行execute方法分下面4种情况。1）如果当前运行的线程少于corePoolSize，则创建新线程来执行任务（注意，执行
        这一步骤需要获取全局锁）。2）如果运行的线程等于或多于corePoolSize，则将任务加入BlockingQueue。3）如果无法将任务加入
        BlockingQueue（队列已满），则创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。4）如果创建新线程将使当前运行的
        线程超出maximumPoolSize，任务将被拒绝，并调用RejectedExecutionHandler.rejectedExecution()方法
    线程池创建线程时，会将线程封装成工作线程Worker，Worker在执行完任务后，还会循环获取工作队列里的任务来执行。我们可以从Worker类
        的run()方法里看到这点。
    ####9.2线程池的使用
    创建一个线程池时需要输入几个参数，如下。1）corePoolSize（线程池的基本大小）：当提交一个任务到线程池时，线程池会创建一个线程来
        执行任务，即使其他空闲的基本线程能够执行新任务也会创建线程，等到需要执行的任务数大于线程池基本大小时就不再创建。如果调用了
        线程池的prestartAllCoreThreads()方法，线程池会提前创建并启动所有基本线程。2）runnableTaskQueue（任务队列）：用于保存等
        待执行的任务的阻塞队列。可以选择以下几个阻塞队列。3）maximumPoolSize（线程池最大数量）：线程池允许创建的最大线程数。如果
        队列满了，并且已创建的线程数小于最大线程数，则线程池会再创建新的线程执行任务。值得注意的是，如果使用了无界的任务队列这个
        参数就没什么效果。4）ThreadFactory：用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字。
        5）RejectedExecutionHandler（饱和策略）：当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新
        任务。这个策略默认情况下是AbortPolicy，表示无法处理新任务时抛出异常
    可以使用两个方法向线程池提交任务，分别为execute()和submit()方法。execute()方法用于提交不需要返回值的任务，所以无法判断任务是
        否被线程池执行成功。submit()方法用于提交需要返回值的任务。线程池会返回一个future类型的对象，通过这个future对象可以判断任
        务是否执行成功，并且可以通过future的get()方法来获取返回值，get()方法会阻塞当前线程直到任务完成，而使用
        get（long timeout，TimeUnit unit）方法则会阻塞当前线程一段时间后立即返回，这时候有可能任务没有执行完。
    可以通过调用线程池的shutdown或shutdownNow方法来关闭线程池。它们的原理是遍历线程池中的工作线程，然后逐个调用线程的interrupt
        方法来中断线程，所以无法响应中断的任务可能永远无法终止。但是它们存在一定的区别，shutdownNow首先将线程池的状态设置成STOP，
        然后尝试停止所有的正在执行或暂停任务的线程，并返回等待执行任务的列表，而shutdown只是将线程池的状态设置成SHUTDOWN状态，然
        后中断所有没有正在执行任务的线程。
    要想合理地配置线程池，就必须首先分析任务特性，可以从以下几个角度来分析。❑ 任务的性质：CPU密集型任务、IO密集型任务和混合型任务。
        ❑ 任务的优先级：高、中和低。❑ 任务的执行时间：长、中和短。❑ 任务的依赖性：是否依赖其他系统资源，如数据库连接。
    建议使用有界队列。有界队列能增加系统的稳定性和预警能力，可以根据需要设大一点儿，比如几千。
    如果在系统中大量使用线程池，则有必要对线程池进行监控，方便在出现问题时，可以根据线程池的使用状况快速定位问题。可以通过线程池
        提供的参数进行监控，在监控线程池的时候可以使用以下属性。❑ taskCount：线程池需要执行的任务数量。❑ completedTaskCount：线
        程池在运行过程中已完成的任务数量，小于或等于taskCount。❑ largestPoolSize：线程池里曾经创建过的最大线程数量。通过这个数
        据可以知道线程池是否曾经满过。如该数值等于线程池的最大大小，则表示线程池曾经满过。❑ getPoolSize：线程池的线程数量。如果
        线程池不销毁的话，线程池里的线程不会自动销毁，所以这个大小只增不减。❑ getActiveCount：获取活动的线程数。
###第十章Executor框架
    在Java中，使用线程来异步执行任务。Java线程的创建与销毁需要一定的开销，如果我们为每一个任务创建一个新线程来执行，这些线程的创
        建与销毁将消耗大量的计算资源。同时，为每一个任务创建一个新线程来执行，这种策略可能会使处于高负荷状态的应用最终崩溃。        
    ####10.1Excutor框架简介
    Executor框架的两级调度模型：在上层，Java多线程程序通常把应用分解为若干个任务，然后使用用户级的调度器（Executor框架）将这些任
        务映射为固定数量的线程；在底层，操作系统内核将这些线程映射到硬件处理器上
    Executor框架主要由3大部分组成如下。❑ 任务。包括被执行任务需要实现的接口：Runnable接口或Callable接口。
        ❑ 任务的执行。包括任务执行机制的核心接口Executor，以及继承自Executor的ExecutorService接口。Executor框架有两个关键类实
        现了ExecutorService接口（ThreadPoolExecutor和ScheduledThreadPoolExecutor）。
        ❑ 异步计算的结果。包括接口Future和实现Future接口的FutureTask类。
    ❑ Executor是一个接口，它是Executor框架的基础，它将任务的提交与任务的执行分离开来。
    ❑ ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务。
    ❑ ScheduledThreadPoolExecutor是一个实现类，可以在给定的延迟后运行命令，或者定期执行命令。ScheduledThreadPoolExecutor比Timer更灵活，功能更强大。
    ❑ Future接口和实现Future接口的FutureTask类，代表异步计算的结果。
    ❑ Runnable接口和Callable接口的实现类，都可以被ThreadPoolExecutor或Scheduled-ThreadPoolExecutor执行。
    Executor框架的主要成员：ThreadPoolExecutor、ScheduledThreadPoolExecutor、Future接口、Runnable接口、Callable接口和Executors。
    ####10.2ThreadPoolExecutor详解
    ❑ corePool：核心线程池的大小。❑ maximumPool：最大线程池的大小。❑ BlockingQueue：用来暂时保存任务的工作队列。
        ❑ RejectedExecutionHandler：当ThreadPoolExecutor已经关闭或ThreadPoolExecutor已经饱和时（达到了最大线程池大小且工作队
        列已满），execute()方法将要调用的Handler。
    ####10.3ScheduledThreadPoolExecutor详解
    ScheduledThreadPoolExecutor继承自ThreadPoolExecutor。它主要用来在给定的延迟之后运行任务，或者定期执行任务。
        ScheduledThreadPoolExecutor的功能与Timer类似，但ScheduledThreadPoolExecutor功能更强大、更灵活。Timer对应的是单个后台
        线程，而ScheduledThreadPoolExecutor可以在构造函数中指定多个对应的后台线程数。
    ScheduledFutureTask主要包含3个成员变量，如下。❑ long型成员变量time，表示这个任务将要被执行的具体时间。
        ❑ long型成员变量sequenceNumber，表示这个任务被添加到ScheduledThreadPoolExecutor中的序号。
        ❑ long型成员变量period，表示任务执行的间隔周期。
    ####10.4 FutureTask详解
    FutureTask除了实现Future接口外，还实现了Runnable接口。因此，FutureTask可以交给Executor执行，也可以由调用线程直接执行
        （FutureTask.run()）。根据FutureTask.run()方法被执行的时机，FutureTask可以处于下面3种状态。未启动，已启动，已完成
    可以把FutureTask交给Executor执行；也可以通过ExecutorService.submit（…）方法返回一个FutureTask，然后执行FutureTask.get()方
        法或FutureTask.cancel（…）方法。除此以外，还可以单独使用FutureTask。    
    
    
    
    
    
    
       